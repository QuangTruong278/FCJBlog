[{"uri":"https://quangtruong278.github.io/FCJBlog/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Văn Quang Trường\nSố điện thoại: 0765243702\nEmail: truongvqse182458@fpt.edu.vn\nTrường: Đại học FPT\nNgành: Trí tuệ nhân tạo\nLớp:\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 8/9/2025 đến ngày 28/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Tại trang này, tôi sẽ giới thiệu tổng quan về nhật ký thực tập của mình. Quá trình thực tập diễn ra trong 12 tuần (từ 08/09 đến 28/11), trong thời gian đó tôi đã thực hiện các dự án thực tế để nắm vững các kiến thức về Điện toán đám mây và DevOps trên nền tảng AWS.\nDưới đây là tóm tắt nội dung công việc theo từng tuần:\nTuần 1: Làm quen với AWS và các dịch vụ cơ bản (EC2, CLI)\nTuần 2: Tìm hiểu sâu về Networking (VPC) \u0026amp; Storage (S3)\nTuần 3: Cơ sở dữ liệu (RDS) \u0026amp; Tích hợp Web Server\nTuần 4: Cân bằng tải (ALB) \u0026amp; Tự động mở rộng (Auto Scaling)\nTuần 5: Quản lý định danh (IAM) \u0026amp; Bảo mật hệ thống\nTuần 6: Tích hợp dịch vụ Email với Amazon SES\nTuần 7: Cơ sở hạ tầng dưới dạng mã (IaC) với Terraform\nTuần 8: Xây dựng quy trình CI/CD với AWS Developer Tools\nTuần 9: Container hóa ứng dụng với Docker \u0026amp; Amazon ECR\nTuần 10: Điện toán Serverless với Lambda \u0026amp; API Gateway\nTuần 11: Giám sát \u0026amp; Ghi log hệ thống với Amazon CloudWatch\nTuần 12: Tổng kết dự án, Tối ưu hóa \u0026amp; Dọn dẹp tài nguyên\n"},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/1-worklog/1.1-week1/","title":"Báo cáo công việc Tuần 1","tags":[],"description":"","content":"Mục tiêu Tuần 1: Kết nối và làm quen với các thành viên của First Cloud Journey. Hiểu các dịch vụ AWS cơ bản, cách sử dụng Console \u0026amp; CLI. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Làm quen với các thành viên FCJ - Đọc và ghi nhớ nội quy thực tập 08/09/2025 08/09/2025 3 - Tìm hiểu AWS và các nhóm dịch vụ: + Compute + Storage + Networking + Database 09/09/2025 09/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo tài khoản AWS Free Tier - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo tài khoản + Cài đặt \u0026amp; cấu hình AWS CLI 10/09/2025 10/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Học cơ bản về EC2: + Instance types, AMI, EBS - Các phương thức SSH vào EC2 - Tìm hiểu Elastic IP 11/09/2025 12/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Khởi tạo EC2 instance + Kết nối SSH + Gắn EBS volume 12/09/2025 12/09/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được trong Tuần 1: Hiểu rõ AWS là gì và nắm vững các nhóm dịch vụ cơ bản (Compute, Storage, Networking, Database). Đăng ký và cấu hình thành công tài khoản AWS Free Tier. Làm quen với giao diện quản trị AWS Management Console. Cài đặt và cấu hình AWS CLI trên máy cá nhân (Access Key, Secret Key). Sử dụng AWS CLI để thực hiện các thao tác cơ bản (Kiểm tra thông tin tài khoản, xem danh sách region, quản lý Key Pair). "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/5-workshop/5.3-compute/5.3.1-ec2/","title":"Amazon EC2","tags":[],"description":"","content":"Khởi tạo EC2 Instance Các bước thực hiện 1. Tạo Security Group Tạo SG cho phép HTTP (80), HTTPS (443), SSH (22) và Custom TCP (8080 - port của Spring Boot). 2. Launch Instance Truy cập EC2 Dashboard -\u0026gt; Launch Instances.\nĐặt tên: Auction-Backend.\nChọn OS: Amazon Linux 2023 hoặc Ubuntu. Chọn Instance Type: t3.medium (như đề xuất).\nChọn Key Pair (tạo mới nếu chưa có).\nNetwork settings: Chọn VPC, Public Subnet, và Security Group đã tạo. Configure storage (mặc định 8GB hoặc tăng lên nếu cần).\nAdvanced details:\nIAM instance profile: Chọn Auction-EC2-Role. Nhấn Launch instance.\n3. Gán Elastic IP (Tùy chọn) Nếu bạn muốn IP Public cố định.\nVào Elastic IPs -\u0026gt; Allocate Elastic IP address. Chọn IP vừa tạo -\u0026gt; Associate Elastic IP address. Chọn Instance vừa tạo. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/5-workshop/5.2-database-storage/5.2.1-rds/","title":"Amazon RDS","tags":[],"description":"","content":"Khởi tạo Amazon RDS (MySQL) Chúng ta sẽ sử dụng Amazon RDS MySQL để lưu trữ dữ liệu chính của hệ thống.\nCác bước thực hiện 1. Tạo Security Group cho RDS Trước tiên, cần tạo Security Group cho phép kết nối cổng 3306 từ EC2. 2. Tạo Subnet Group Vào RDS Dashboard -\u0026gt; Subnet groups -\u0026gt; Create DB subnet group. Chọn VPC và các Private Subnet đã tạo. 3. Tạo Database Chọn Databases -\u0026gt; Create database.\nChọn Standard create -\u0026gt; MySQL.\nChọn phiên bản (Engine Version). Chọn Free tier (nếu dùng tài khoản mới) hoặc Dev/Test. Đặt tên DB instance identifier, Master username và password. Chọn Instance class (ví dụ db.t3.micro).\nCấu hình Storage. Cấu hình Connectivity: Chọn VPC, Subnet Group, và Security Group đã tạo. Cấu hình xác thực (Password authentication). Nhấn Create database. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/3-blogstranslated/3.4-blog4/","title":"Blog 4","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/3-blogstranslated/3.5-blog5/","title":"Blog 5","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/3-blogstranslated/3.6-blog6/","title":"Blog 6","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/5-workshop/5.5-deploy/5.5.1-setup-ec2/","title":"Cài đặt môi trường EC2 instance","tags":[],"description":"","content":"Cài đặt môi trường cho máy chủ EC2 Trong phần này, chúng ta sẽ thực hiện gán IAM Role cho EC2 và cài đặt các phần mềm cần thiết như Java và MariaDB để chuẩn bị cho việc triển khai ứng dụng.\n1. Gán IAM role cho EC2 Để EC2 instance có quyền truy cập vào các dịch vụ AWS khác (ví dụ: Session Manager để kết nối mà không cần mở port SSH, hoặc truy cập S3, RDS), chúng ta cần gán IAM Role phù hợp.\nTruy cập vào EC2 Dashboard, chọn Instance mà bạn vừa khởi tạo. Chọn Actions -\u0026gt; Security -\u0026gt; Modify IAM role. Chọn IAM Role đã tạo ở các bước trước (ví dụ: EC2RoleForSSM) và nhấn Update IAM role. 2. Cài đặt môi trường Kết nối vào EC2 Instance (sử dụng Session Manager hoặc SSH). Sau đó thực hiện lần lượt các bước sau:\n2.1. Cập nhật hệ thống Chạy lệnh sau để cập nhật các gói phần mềm mới nhất:\nsudo dnf update -y 2.2. Cài đặt Java Ứng dụng của chúng ta chạy trên nền tảng Java, do đó cần cài đặt Java Development Kit (JDK). Ở đây chúng ta sử dụng Amazon Corretto 21 (phiên bản headless phù hợp hơn cho giao diện dòng lệnh không cần đồ hoạ).\nsudo dnf install java-21-amazon-corretto-headless -y Kiểm tra phiên bản Java sau khi cài đặt:\njava -version 2.3. Cài đặt MariaDB Client và Khởi tạo Database Cài đặt MariaDB client để có thể kết nối và thao tác với RDS.\nsudo dnf install mariadb105 -y Kết nối đến RDS database instance mà bạn đã tạo. Thay thế \u0026lt;rds-endpoint\u0026gt;, \u0026lt;username\u0026gt; bằng thông tin thực tế của bạn:\nmysql -h \u0026lt;rds-endpoint\u0026gt; -u \u0026lt;username\u0026gt; -p Sau khi nhập mật khẩu thành công, thực hiện tạo database cho ứng dụng:\nCREATE DATABASE tickets; SHOW DATABASES; 2.4. Cài đặt service để khởi chạy ứng dụng Java Springboot tự động Chạy lệnh sau để tạo file service\nsudo nano /etc/systemd/system/\u0026lt;service-name\u0026gt;.service Nhập nội dung file service, cấu hình biến môi trường cho ứng dụng\nDùng tổ hợp phím Ctrl + O, Enter và Ctrl + X để lưu lại và thoát\nDùng các lệnh sau để áp dụng những thay đổi\nsudo systemctl daemon-reload sudo systemctl restart \u0026lt;service-name\u0026gt; Kiểm tra trạng thái bằng lệnh status Dùng lệnh enable để service có thể tự động chạy cùng lúc mỗi khi EC2 instance start\nsudo systemctl enable \u0026lt;service-name\u0026gt; Lệnh chỉnh múi giờ để đồng bộ (trong trường hợp ứng dụng Java cần có múi giờ phù hợp với giờ Việt Nam)\nsudo timedatectl set-timezone Asia/Ho_Chi_Minh Kiểm tra kết quả bằng lệnh\ndate "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/5-workshop/5.4-distribution/5.4.1-ssl-certificate/","title":"Certificate Manager","tags":[],"description":"","content":"AWS Certificate Manager (ACM) Để sử dụng HTTPS, chúng ta cần chứng chỉ SSL.\nCác bước thực hiện Truy cập ACM Console.\nChọn Request a certificate.\nChọn Request a public certificate. Nhập Domain name (ví dụ *.example.com). Chọn DNS validation.\nNhấn Request.\nSau khi request, nhấn vào ID của chứng chỉ, chọn Create records in Route 53 để xác thực tự động. Đợi trạng thái chuyên sang Issued.\n"},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/5-workshop/5.1-preparation/","title":"Chuẩn bị","tags":[],"description":"","content":"Chuẩn bị môi trường Trước khi đi vào cài đặt các dịch vụ chính, chúng ta cần chuẩn bị lớp mạng (Networking) và quyền truy cập (IAM) cho các tài nguyên.\nNội dung VPC: Tạo Virtual Private Cloud để cô lập mạng cho hệ thống. IAM: Tạo các Role cần thiết cho EC2 truy cập S3, Rekognition, Textract. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/5-workshop/5.5-deploy/5.5.2-gitlab/","title":"GitLab CI","tags":[],"description":"","content":"Cấu hình GitLab CI Các bước thực hiện 1. Chuẩn bị biến môi trường (Variables) Vào Settings -\u0026gt; CI/CD -\u0026gt; Variables trên GitLab Repository. Thêm các biến cần thiết:\nEC2_IP SSH_PRIVATE_KEY 2. File cấu hình .gitlab-ci.yml Tạo file .gitlab-ci.yml tại thư mục gốc của dự án. Quy trình gồm:\nBuild: Build file JAR (Spring Boot) hoặc Docker Image. Deploy: Copy file lên EC2 và restart service. Ví dụ pipeline thành công: "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/5-workshop/5.1-preparation/5.1.1-vpc/","title":"Tạo VPC","tags":[],"description":"","content":"Khởi tạo Virtual Private Cloud (VPC) Hệ thống sẽ chạy bên trong một mạng riêng ảo (VPC) để đảm bảo bảo mật và cô lập tài nguyên. Chúng ta sẽ tạo VPC với các Public Subnet (cho Load Balancer) và Private Subnet (cho EC2, RDS).\nCác bước thực hiện Truy cập vào AWS Console và tìm kiếm dịch vụ VPC. Chọn Create VPC. Chọn cấu hình VPC and more để tạo nhanh VPC cùng các subnet và Route Table. Điền các thông tin: Name tag: Auction-VPC IPv4 CIDR block: 10.0.0.0/16 Number of Availability Zones (AZs): 2 (để đảm bảo tính sẵn sàng cao) Number of public subnets: 2 Number of private subnets: 2 NAT gateways: None (hoặc 1 per AZ nếu cần EC2 trong private subnet truy cập internet để tải package, nhưng để tiết kiệm chi phí trong bài lab này có thể chọn None hoặc 1). Nhấn Create VPC. Đợi quá trình khởi tạo hoàn tất. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/1-worklog/1.2-week2/","title":"Báo cáo công việc Tuần 2","tags":[],"description":"","content":"Mục tiêu Tuần 2: Tìm hiểu sâu về Mạng trong AWS (VPC, Subnet, Route Table, Internet Gateway). Hiểu và thực hành dịch vụ lưu trữ AWS Storage Service (S3) và các tính năng (Versioning, Lifecycle, Hosting). Triển khai một trang web tĩnh (static website) trên S3. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Học kiến trúc VPC: CIDR, Subnets (Public vs Private), Internet Gateway.\n- Thực hành: Tạo một VPC tùy chỉnh với 1 Public Subnet và 1 Private Subnet. 15/09/2025 15/09/2025 https://docs.aws.amazon.com/vpc/ 3 - Cấu hình Route Tables và Security Groups (Quy tắc Inbound/Outbound).\n- Khởi tạo EC2 trong Public Subnet và thử kết nối SSH.\n- Tìm hiểu cơ bản về NAT Gateway. 16/09/2025 16/09/2025 https://docs.aws.amazon.com/vpc/ 4 - Học các khái niệm Amazon S3: Buckets, Objects, Classes (Standard, IA, Glacier).\n- Thực hành: Tạo S3 Buckets thông qua Console và CLI. 17/09/2025 17/09/2025 https://docs.aws.amazon.com/s3/ 5 - Tính năng nâng cao S3: Bật Versioning, Cấu hình Lifecycle Rules.\n- Tìm hiểu về Bucket Policies và ACLs. 18/09/2025 18/09/2025 https://docs.aws.amazon.com/s3/ 6 - Mini-Project: Host một trang web tĩnh trên Amazon S3.\n- Upload file HTML/CSS.\n- Cấu hình \u0026ldquo;Static website hosting\u0026rdquo; và mở quyền truy cập public. 19/09/2025 19/09/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được trong Tuần 2: Thiết kế và tạo thành công một Virtual Private Cloud (VPC) tùy chỉnh với phân đoạn mạng chính xác (Public/Private subnets). Cấu hình Security Groups để kiểm soát chặt chẽ lưu lượng truy cập (ví dụ: chỉ cho phép SSH từ IP cụ thể). Làm chủ các kiến thức cơ bản về Amazon S3: Tạo bucket và quản lý đối tượng bằng cả Console và CLI. Thực hiện bảo vệ dữ liệu bằng Versioning. Tối ưu hóa chi phí bằng Lifecycle policies (chuyển dữ liệu sang Glacier). Host thành công một trang web tĩnh sử dụng S3 mà không cần máy chủ. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/5-workshop/5.2-database-storage/5.2.2-elasticache/","title":"Amazon ElastiCache","tags":[],"description":"","content":"Khởi tạo Amazon ElastiCache (Redis) Redis giúp cache các truy vấn thường xuyên và lưu session người dùng.\nCác bước thực hiện 1. Tạo Subnet Group Vào ElastiCache Dashboard -\u0026gt; Subnet groups -\u0026gt; Create subnet group. 2. Tạo Security Group Tạo Security Group cho phép cổng 6379 từ EC2. 3. Tạo Redis Cluster Chọn Redis OSS caches -\u0026gt; Create cache.\nChọn Configure and create a new cluster.\nChọn Cluster mode disabled (để đơn giản và tiết kiệm chi phí). Cấu hình Redis info Cấu hình Node type, ví dụ cache.t3.micro. Chọn Subnet group. Chọn Security Group. Nhấn Create.\n"},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/5-workshop/5.4-distribution/5.4.2-alb/","title":"Application Load Balancer","tags":[],"description":"","content":"Application Load Balancer (ALB) ALB sẽ phân phối traffic tới các EC2 instance và xử lý SSL termination.\nCác bước thực hiện 1. Tạo Security Group cho ALB Cho phép HTTP (80) và HTTPS (443) từ 0.0.0.0/0. 2. Tạo Target Group Tạo Target Group loại Instances. Protocol HTTP/8080 (Port backend). Register EC2 instances vào Target Group. 3. Tạo Load Balancer Vào Load Balancers -\u0026gt; Create load balancer.\nChọn Application Load Balancer.\nChọn VPC và Public Subnets.\nChọn Security Group vừa tạo.\nCấu hình Listener:\nHTTP:80 -\u0026gt; Redirect to HTTPS (được khuyến nghị). HTTPS:443 -\u0026gt; Forward to Target Group. Tại phần HTTPS listener, chọn ACM Certificate đã tạo. Nhấn Create load balancer.\nSau khi tạo Load Balancer, ta có thể cấu hình lại security group cho EC2 instance chỉ nhận inbound rule từ Load Balancer "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Auction system build in AWS Cloud infrastructure Hệ thống web đấu giá xây dựng trên nền tảng điện toán đám mây của Amazon Web Service 1. Tóm tắt điều hành Auction system được thiết kế bởi sinh viên FPTU tại TP. Hồ Chí Minh và vận hành trên nền tảng Cloud AWS. Nền tảng tận dụng các dịch vụ AWS để xây dựng một sàn đấu giá trực tuyến với giao diện thân thiện, dễ dàng sử dụng phù hợp với tất cả mọi người\n2. Tuyên bố vấn đề Vấn đề hiện tại\nHiện tại những hệ thống đấu giá vẫn chưa tiếp cận được đến nhiều người bởi vì sự khó tiếp cận. Dự án này ra đời để mang đến một nền tảng đấu giá trực tiếp minh bạch, thân thiện dễ tiếp cận đến mọi người.\nGiải pháp\nNền tảng sử dụng AWS CloudFront và S3 Storage kết hợp ReactJS cung cấp giao diện web , với máy chủ EC2 đảm nhiệm toàn bộ công việc xử lí trên nền tảng Springboot, Amazon S3 để lưu trữ dữ liệu công khai và riêng tư, AWS RDS để lưu trữ cơ sở dữ liệu. Kết hợp cùng Amazon Rekognition và Textract để trích xuất thông tin, xác minh thông tin người dùng để đảm bảo tính công bằng. Với nền tảng này, người dùng có thể đăng ký tài khoản mới, xác thực và tham gia những phiên đấu giá hấp dẫn trên nền tảng.\nLợi ích và hoàn vốn đầu tư (ROI)\nDự án mang đến một nền tảng đấu giá trực tuyến dễ dàng tiếp cận đến mọi người. Chi phí hàng tháng ước tính 59.37 USD (theo AWS Pricing Calculator). Không phát sinh chi phí phát triển thêm.\n3. Kiến trúc giải pháp Nền tảng áp dụng kiến trúc AWS để quản lý dữ liệu. Dữ liệu công khai được lưu trữ trong S3 public bucket và hiển thị đến người dùng qua CloudFront và S3 với ReactJS. Mọi thao tác xử lí được thực hiện trên EC2 với nền tảng Springboot. Các thông tin định danh được xử lí bởi Amazon Rekognition và Textract sau đó lưu trữ trong S3 private bucket\nDịch vụ AWS sử dụng\nAWS VPC: Tạo môi trường mạng ảo riêng tư. AWS Route 53: Điều hướng traffic của người dùng. AWS CloudFront: CDN giúp tăng tốc độ tải trang, giảm độ trễ truy cập web. AWS Load Balancing: Nhận request từ internet và điều hướng đến EC2, ổn định ứng dụng. Amazon EC2: Chạy ứng dụng springboot để xử lí backend, giao tiếp với database (RDS), cache query (ElastiCache), gọi các service AI (Rekognition, Textract) và xử lí đấu giá. Amazon S3: Hosting Frontend: Lưu trữ source code của frontend (ReactJS, Tailwind) để CloudFront phân phối. Data storage: 2 bucket (public/private) để lưu trữ ảnh người dùng tải lên phục vụ cho đấu giá và xác minh tài khoản. Amazon ElastiCache: Bộ nhớ đệm, giúp lưu trữ truy vấn giảm tải cho database và tăng tốc độ phản hồi API. Amazon RDS: Lưu trữ dữ liệu chính của hệ thống, được đặt tại private subnet. Amazon Rekognition: Dịch vụ phân tích hình ảnh bằng AI, thực hiện so sánh khuôn mặt (Face Compare) giữa ảnh chụp selfie và ảnh trên giấy tờ tùy thân để xác minh danh tính (eKYC). Amazon Textract: Dịch vụ trích xuất văn bản từ tài liệu. Hệ thống sử dụng Textract để tự động đọc (OCR) và bóc tách thông tin từ ảnh chụp giấy tờ tùy thân để điền tự động cho người dùng. Amazon SES: Backend sử dụng dịch vụ này để gửi email xác thực tài khoản (OTP), thông báo thắng đấu giá hoặc các thông báo hệ thống khác tới người dùng. Amazon CloudWatch: Hệ thống giám sát và quản lý log. Thiết kế thành phần\nTiếp nhận dữ liệu: Dữ liệu từ người dùng. Lưu trữ dữ liệu: Dữ liệu lưu ở 2 S3 bucket (1 cho public và 1 cho private - truy cập qua presigned url) Xử lý dữ liệu: EC2 thực hiện việc xử lí dữ liệu. Giao diện web: Amazon S3 lưu trữ ứng dụng ReactJS. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án gồm các giai đoạn:\nNghiên cứu và vẽ kiến trúc: Nghiên cứu và thiết kế kiến trúc AWS, xác định các dịch vụ sẽ sử dụng, thiết kế database. Tính toán chi phí và kiểm tra tính khả thi: Sử dụng AWS Pricing Calculator để ước tính và điều chỉnh. Phát triển, kiểm thử, triển khai: Lập trình Springboot và ứng dụng ReactJS, sau đó kiểm thử ở môi trường local. Triển khai trên môi trường Cloud AWS: Thiết lập Gitlab CI, thiết lập môi trường cloud và triển khai. Yêu cầu kỹ thuật\nJava 21 Springboot AWS SDK (S3, Rekognition, Textract, SES) MySQL RDS ReactJS/Vite/TypeScript/Tailwind Gitlab, Gitlab runner CI Postman, CloudWatch 5. Lộ trình \u0026amp; Mốc triển khai Trước thực tập (Tháng 0): 1 tháng lên kế hoạch và đánh giá trạm cũ. Thực tập (Tháng 1–3): Tháng 1: Học AWS và thiết kế kiến trúc, thiết kế database, triển khai xây dựng API. Tháng 2: Triển khai xây dựng API, xây dựng giao diện. Tháng 3: Triển khai trên môi trường cloud , kiểm thử, đưa vào sử dụng. 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nChi phí hạ tầng\nAmazon Route53: $0.5/tháng (1 hosted zone) S3 Standard: $0.72/tháng (10 GB, 30000 request GET, 1000 request PUT, 5 GB Transfer out) Application Load Balancer: $18.80/tháng (data process 50GB) Amazon EC2 (t3.medium): $16.35/tháng (3yr, no upfront) Amazon ElastiCache (cache.t3.micro): $9.49/tháng (3yr, no upfront) Amazon RDS: $8.38/tháng Rekognition: $0.13/tháng (100 FaceCompare) Textract: $5/tháng (200 Pages document) Tổng: $59.37/tháng.\n7. Đánh giá rủi ro Ma trận rủi ro\nMất mạng: Ảnh hưởng lớn, xác suất thấp. Vượt ngân sách: Ảnh hưởng trung bình, xác suất thấp. Chiến lược giảm thiểu\nChi phí: Cảnh báo ngân sách AWS, tối ưu dịch vụ. Kế hoạch dự phòng\nCó backup định kì đề phòng xảy ra sự cố. Sử dụng CloudFormation để khôi phục cấu hình liên quan đến chi phí. 8. Kết quả kỳ vọng Giá trị dài hạn: Có thể tái sử dụng cho các dự án khác trong tương lai.\n"},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/4-eventparticipated/4.1-event1/","title":"Báo cáo sự kiện: AWS GenAI &amp; Data","tags":[],"description":"","content":"Báo cáo tổng hợp: “AWS GenAI \u0026amp; Data Revolution” Mục tiêu sự kiện Nắm bắt lộ trình chiến lược để áp dụng Generative AI trên nền tảng AWS. Học cách xây dựng nền tảng dữ liệu thống nhất (Unified Data Foundation) để hỗ trợ các tác vụ AI và phân tích. Khám phá Vòng đời phát triển phần mềm định hướng AI (AI-DLC) và tương lai của việc triển khai phần mềm. Nắm vững các phương pháp bảo mật ứng dụng GenAI và tận dụng sức mạnh của AI Agents. Diễn giả Keynote \u0026amp; Panelists:\nEric Yeo – Tổng giám đốc quốc gia AWS (Việt Nam, Campuchia, Lào \u0026amp; Myanmar) Jaime Valles – Phó chủ tịch, Tổng giám đốc khu vực Châu Á - Thái Bình Dương \u0026amp; Nhật Bản, AWS Dr. Jens Lottner – CEO, Techcombank Ms. Trang Phung – CEO \u0026amp; Co-Founder, U2U Network Jeff Johnson – Giám đốc điều hành khu vực ASEAN, AWS (Điều phối) Technical Track Speakers:\nJun Kai Loke – Chuyên gia AI/ML, AWS Kien Nguyen – Kiến trúc sư giải pháp (Solutions Architect), AWS Binh Tran – Kiến trúc sư giải pháp cấp cao, AWS Taiki Dang – Kiến trúc sư giải pháp, AWS Michael Armentano – Chuyên gia GTM toàn cầu, AWS Nội dung chính (Highlights) Điều hướng cuộc cách mạng GenAI (Executive Panel) Chiến lược lãnh đạo: Thảo luận về cách các nhà lãnh đạo điều hành tổ chức qua sự phát triển nhanh chóng của GenAI. Văn hóa đổi mới: Chia sẻ từ ELSA Corp, Nexttech Group và TymeX về việc gắn kết sáng kiến AI với mục tiêu kinh doanh và quản lý thay đổi tổ chức. Xây dựng nền tảng dữ liệu thống nhất (Unified Data Foundation) Hạ tầng: Các chiến lược xây dựng nền tảng dữ liệu có khả năng mở rộng trên AWS, tối ưu cho AI/Analytics. Thành phần cốt lõi: Đi sâu vào quy trình nhập liệu (ingestion), lưu trữ, xử lý và quản trị dữ liệu. Mục tiêu: Đảm bảo tổ chức có thể quản lý hiệu quả dữ liệu để \u0026ldquo;nuôi\u0026rdquo; các sáng kiến AI tiên tiến. Vòng đời phát triển phần mềm định hướng AI (AI-DLC) Thay đổi tư duy: Chuyển dịch từ việc coi \u0026ldquo;AI là trợ lý\u0026rdquo; sang \u0026ldquo;AI là cộng sự trung tâm\u0026rdquo;. Tích hợp: Kết hợp khả năng thực thi của AI với sự giám sát của con người để cải thiện đáng kể tốc độ và chất lượng phát triển phần mềm. Bảo mật ứng dụng Generative AI Bảo mật đa lớp: Giải quyết thách thức bảo mật tại các lớp hạ tầng, mô hình (model) và ứng dụng. Best Practices: Triển khai kiến trúc Zero-trust, mã hóa, giám sát liên tục và kiểm soát truy cập chi tiết để bảo vệ tính toàn vẹn dữ liệu. Hơn cả tự động hóa: AI Agents Nhân tố tăng năng suất: AI Agents đang tiến hóa từ các công cụ đơn giản thành các \u0026ldquo;đối tác thông minh\u0026rdquo;. Tính tự chủ: Các agent này có thể học hỏi, thích nghi và thực thi các tác vụ phức tạp một cách tự chủ, chuyển đổi vận hành từ thủ công sang hiệu quả theo cấp số nhân. Bài học rút ra (Key Takeaways) Tư duy chiến lược Dữ liệu là chìa khóa: Một nền tảng dữ liệu thống nhất, vững chắc là điều kiện tiên quyết cho bất kỳ chiến lược GenAI thành công nào. Bảo mật ngay từ đầu: Bảo mật không thể là bước sau cùng; nó phải được nhúng vào lớp model và hạ tầng (Zero Trust). Tiến hóa kỹ thuật AI-DLC: Quy trình phát triển phần mềm đang thay đổi căn bản. Cần thích nghi với việc làm việc cùng AI như một cộng sự chứ không chỉ là công cụ hỗ trợ. Agentic Workflow: Tương lai thuộc về AI Agents có khả năng suy luận và hành động, thay vì chỉ tạo sinh văn bản. Ứng dụng vào công việc Rà soát chiến lược dữ liệu: Đánh giá lại hạ tầng dữ liệu hiện tại để đảm bảo tính thống nhất và sẵn sàng cho AI (dựa trên AWS best practices). Thử nghiệm AI Agents: Nghiên cứu xây dựng các AI Agents đơn giản cho các tác vụ vận hành lặp đi lặp lại để tăng năng suất team. Kiểm toán bảo mật: Xem xét lại các biện pháp bảo mật cho các mô hình AI/ML đang thử nghiệm hoặc vận hành. Áp dụng AI-DLC: Khuyến khích team tích hợp sâu hơn các công cụ AI coding vào quy trình dev để cải thiện tốc độ. Trải nghiệm sự kiện Tham gia vào track \u0026ldquo;Gen AI and Data\u0026rdquo; đã mang lại cho tôi một lộ trình rõ ràng về tương lai công nghệ trên nền tảng AWS.\nGóc nhìn từ lãnh đạo Phiên thảo luận với các lãnh đạo từ Techcombank và ELSA Corp thực sự truyền cảm hứng, cho thấy GenAI không chỉ là xu hướng kỹ thuật mà là động lực kinh doanh cốt lõi đòi hỏi sự thay đổi văn hóa.\nĐi sâu vào kỹ thuật Tôi rất ấn tượng với phiên AI-Driven Development Lifecycle (AI-DLC). Nó đã thay đổi quan điểm của tôi về cách phần mềm sẽ được xây dựng trong tương lai - nơi AI là người cộng tác chứ không chỉ là người giúp việc.\nĐón đầu xu hướng Bài chia sẻ về AI Agents của Michael Armentano đã mở ra cái nhìn mới về sự khác biệt giữa tự động hóa đơn thuần và các tác nhân thông minh. Điều này thúc đẩy tôi tìm hiểu thêm về cách xây dựng các Autonomous Agents trên AWS.\nMột số hình ảnh tại sự kiện Thêm ảnh sự kiện của bạn vào đây\nTổng kết lại, sự kiện là cầu nối quan trọng giữa chiến lược AI cấp cao và các bước kỹ thuật thực tế cần thiết để triển khai nó (Dữ liệu, Bảo mật và Agents).\n"},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/5-workshop/5.2-database-storage/","title":"Database &amp; Storage","tags":[],"description":"","content":"Cài đặt Cơ sở dữ liệu và Lưu trữ Trong phần này, chúng ta sẽ khởi tạo:\nAmazon RDS: Cơ sở dữ liệu quan hệ (MySQL). Amazon ElastiCache: Redis cache. Amazon S3: Lưu trữ object (ảnh, source code). Các dịch vụ này sẽ đóng vai trò backend lưu trữ dữ liệu cho ứng dụng.\n"},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/5-workshop/5.1-preparation/5.1.2-iam/","title":"Tạo IAM Role","tags":[],"description":"","content":"Tạo IAM Role cho EC2 EC2 cần quyền truy cập vào S3 để lấy code/ảnh, và quyền gọi API của Rekognition và Textract. Thay vì lưu Access Key trong code, ta sẽ dùng IAM Role gán cho EC2.\nCác bước thực hiện Truy cập IAM Dashboard. Chọn Roles -\u0026gt; Create role. Tại bước Trusted entity type, chọn AWS service. Tại Use case, chọn EC2. Nhấn Next. Tại bước Add permissions, tìm và chọn các Policy sau: AmazonS3FullAccess (Hoặc policy giới hạn chỉ bucket của pj). AmazonRekognitionFullAccess. AmazonTextractFullAccess. AmazonSSMManagedInstanceCore (Để remote vào EC2 qua Session Manager nếu cần). Nhấn Next. Đặt tên Role là Auction-EC2-Role. Xem lại và nhấn Create role. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/1-worklog/1.3-week3/","title":"Báo cáo công việc Tuần 3","tags":[],"description":"","content":"Mục tiêu Tuần 3: Tìm hiểu về Cơ sở dữ liệu quan hệ được quản lý trên AWS (Amazon RDS). Cấu hình bảo mật mạng giữa Compute (EC2) và Database (RDS). Triển khai một ứng dụng web động đơn giản kết nối với cơ sở dữ liệu. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Học các khái niệm RDS (Multi-AZ, Read Replicas, Backups, Maintenance Window).\n- Thực hành: Tạo một MySQL RDS instance (Free Tier). 22/09/2025 22/09/2025 https://docs.aws.amazon.com/rds/ 3 - Cấu hình Security Groups: Cho phép lưu lượng từ EC2 Security Group vào RDS Security Group trên cổng 3306.\n- Tìm hiểu về RDS endpoints. 23/09/2025 23/09/2025 https://docs.aws.amazon.com/rds/ 4 - Cài đặt LAMP stack (Linux, Apache, MySQL/MariaDB, PHP) trên một EC2 instance.\n- Chuẩn bị một script PHP kết nối mẫu. 24/09/2025 24/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Thực hành: Kết nối ứng dụng PHP trên EC2 tới RDS endpoint.\n- Xử lý sự cố kết nối (Troubleshoot VPC, Subnets, SG). 25/09/2025 25/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Tìm hiểu về RDS Snapshots (Manual vs Automated).\n- Thực hành: Tạo snapshot thủ công và khôi phục (restore) ra một DB instance mới. 26/09/2025 26/09/2025 https://docs.aws.amazon.com/rds/ Kết quả đạt được trong Tuần 3: Khởi tạo thành công một cơ sở dữ liệu MySQL được quản lý hoàn toàn bằng Amazon RDS. Thực hiện các biện pháp bảo mật tốt nhất bằng cách chỉ giới hạn quyền truy cập cơ sở dữ liệu cho Web Server (EC2) thông qua Security Group. Triển khai thành công ứng dụng web động (LAMP stack) trên EC2. Thiết lập kết nối thành công giữa Tầng Ứng dụng (App Tier) và Tầng Dữ liệu (Data Tier). Thực hiện các thao tác sao lưu và khôi phục cơ sở dữ liệu bằng RDS Snapshots. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/5-workshop/5.4-distribution/5.4.3-cloudfront/","title":"Amazon CloudFront","tags":[],"description":"","content":"Amazon CloudFront CloudFront giúp phân phối nội dung tĩnh từ S3 với độ trễ thấp.\nCác bước thực hiện Truy cập CloudFront Console -\u0026gt; Create distribution.\nTại Origin domain, chọn S3 Bucket Frontend. Tại Origin access, chọn Legacy access identities hoặc OAC (Origin Access Control) để hạn chế người dùng truy cập trực tiếp S3. Chọn Create new OAC.\nViewer protocol policy: Redirect HTTP to HTTPS.\nAllowed HTTP methods: GET, HEAD, OPTIONS.\nWAF: Do not enable (để tiết kiệm). Alternate domain name (CNAME): Điền domain frontend (ví dụ www.example.com).\nCustom SSL certificate: Chọn chứng chỉ ACM. Default root object: index.html. Nhấn Create distribution.\nSau khi tạo, nhớ update Bucket Policy của S3 để cho phép OAC truy cập (Console sẽ gợi ý copy policy).\n"},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/5-workshop/5.2-database-storage/5.2.3-s3/","title":"Amazon S3","tags":[],"description":"","content":"Khởi tạo Amazon S3 Buckets Chúng ta cần 3 bucket cho các mục đích khác nhau.\n1. Frontend Bucket Dùng để hosting static web (ReactJS).\nTạo bucket với tên unique. Bỏ chọn Block all public access (vì cần public web). Bật Static website hosting. 2. Public Storage Bucket Lưu ảnh sản phẩm đấu giá (public read).\nTạo bucket. Bỏ chọn Block all public access. Cấu hình Bucket Policy cho phép s3:GetObject. 3. Private Storage Bucket Lưu ảnh giấy tờ tùy thân cho việc xác minh tài khoản (private).\nTạo bucket. Giữ nguyên Block all public access. (Tùy chọn) Cấu hình Server-side encryption. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/4-eventparticipated/4.2-event2/","title":"Báo cáo sự kiện: AI/ML/GenAI on AWS","tags":[],"description":"","content":"Báo cáo tổng hợp: “Hội thảo AI/ML/GenAI on AWS” Mục tiêu sự kiện Có cái nhìn tổng quan về bối cảnh AI/ML tại thị trường Việt Nam. Hiểu về khả năng Machine Learning toàn diện (end-to-end) của Amazon SageMaker. Đi sâu vào Generative AI với Amazon Bedrock (Foundation Models, Agents, Guardrails). Học cách triển khai thực tế thông qua các bài demo trực tiếp trên SageMaker Studio và Bedrock. Diễn giả Đội ngũ Kiến trúc sư Giải pháp AWS (AWS Solutions Architects - Vietnam) Nội dung chính (Highlights) Tổng quan về AWS AI/ML Services (Amazon SageMaker) Nền tảng toàn diện: SageMaker cung cấp một giao diện thống nhất cho toàn bộ vòng đời ML, từ chuẩn bị và gán nhãn dữ liệu đến xây dựng, huấn luyện, tinh chỉnh và triển khai mô hình. Tích hợp MLOps: Nhấn mạnh tầm quan trọng của các tính năng MLOps tích hợp sẵn trong SageMaker giúp chuẩn hóa quy trình vận hành và đảm bảo tính tái lập của mô hình. SageMaker Studio: Demo trực tiếp cho thấy cách quản lý quy trình ML một cách trực quan, giúp cả Data Scientist và Developer đều dễ dàng tiếp cận. Generative AI với Amazon Bedrock Lựa chọn Foundation Models (FMs): So sánh các mô hình khác nhau có sẵn trên Bedrock (Claude, Llama, Titan) và hướng dẫn chọn mô hình phù hợp cho từng trường hợp sử dụng (tốc độ, độ chính xác, chi phí). Kỹ thuật Prompt Engineering: Các phương pháp cải thiện đầu ra của mô hình, bao gồm tư duy chuỗi (Chain-of-Thought) và học từ vài mẫu (Few-shot learning). RAG (Retrieval-Augmented Generation): Giải thích kiến trúc kết nối FMs với cơ sở tri thức nội bộ để giảm thiểu ảo giác (hallucinations) và cung cấp câu trả lời chính xác theo ngữ cảnh doanh nghiệp. Agents \u0026amp; Guardrails: Cách sử dụng Agents cho các tác vụ đa bước và Guardrails để đảm bảo an toàn nội dung. Bài học rút ra (Key Takeaways) Đơn giản hóa quy trình ML SageMaker giúp giảm đáng kể gánh nặng vận hành hạ tầng ML, cho phép team tập trung vào logic của mô hình thay vì việc bảo trì máy chủ. Phổ cập hóa GenAI Amazon Bedrock mang lại trải nghiệm serverless để truy cập các mô hình Foundation hàng đầu chỉ qua một API, loại bỏ nhu cầu quản lý hạ tầng GPU phức tạp. RAG là cốt lõi: Đối với ứng dụng doanh nghiệp, RAG là mẫu thiết kế (pattern) quan trọng nhất để biến GenAI thành công cụ hữu ích và đáng tin cậy. Ứng dụng vào công việc Khám phá SageMaker Canvas: Thử nghiệm các tính năng low-code của SageMaker để tạo nhanh các mô hình dự đoán từ dữ liệu bảng. Xây dựng Prototype RAG: Sử dụng Amazon Bedrock để dựng một chatbot hỏi đáp đơn giản kết nối với tài liệu nội bộ (ví dụ: hướng dẫn thực tập hoặc tài liệu dự án). Luyện tập Prompt Engineering: Áp dụng kỹ thuật \u0026ldquo;Chain-of-Thought\u0026rdquo; để cải thiện chất lượng khi nhờ AI viết code hoặc tài liệu. Trải nghiệm sự kiện Buổi workshop \u0026ldquo;AI/ML/GenAI on AWS\u0026rdquo; là một phiên làm việc cường độ cao và mang tính thực tiễn rất lớn.\nTập trung vào thực hành Khác với các buổi hội thảo lý thuyết, workshop này tập trung nhiều vào Live Demo. Việc tận mắt thấy một GenAI chatbot được xây dựng từ con số 0 bằng Bedrock Agents giúp tôi hình dung rõ ràng cách các thành phần (FMs, Knowledge Bases, Action Groups) kết hợp với nhau.\nBộ công cụ toàn diện Tôi nhận ra AWS có công cụ cho mọi giai đoạn của hành trình AI. Dù là ML truyền thống (SageMaker) hay GenAI tiên tiến (Bedrock), hệ sinh thái đều được tích hợp rất chặt chẽ.\nKết nối (Networking) Phần \u0026ldquo;Ice-breaker\u0026rdquo; và giao lưu đầu giờ giúp tôi kết nối với các lập trình viên và sinh viên khác cùng quan tâm đến AI, mang lại góc nhìn rộng hơn về cách AI đang được áp dụng tại Việt Nam.\nMột số hình ảnh tại sự kiện Thêm ảnh sự kiện của bạn vào đây\nTổng kết lại, buổi workshop đã giải mã những thuật ngữ phức tạp về GenAI và cung cấp một lộ trình kỹ thuật rõ ràng để xây dựng ứng dụng AI trên AWS.\n"},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Getting started with healthcare data lakes: Using microservices Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 2 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 3 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 4 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 5 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 6 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\n"},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/5-workshop/5.3-compute/","title":"Compute","tags":[],"description":"","content":"Khởi tạo Amazon EC2 Amazon EC2 (Elastic Compute Cloud) sẽ là nơi chạy ứng dụng backend (Spring Boot).\nNội dung EC2 Instance: Máy chủ ảo chạy ứng dụng. Security Group: Tường lửa kiểm soát truy cập. Elastic IP: Địa chỉ IP tĩnh (tùy chọn, cần thiết nếu không dùng Load Balancer hoặc cần IP cố định cho outbound). "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/4-eventparticipated/","title":"Các sự kiện đã tham gia","tags":[],"description":"","content":" Trong phần này, tôi liệt kê và mô tả chi tiết các sự kiện và hội thảo kỹ thuật mà tôi đã tham gia trong suốt kỳ thực tập. Những sự kiện này mang lại cơ hội quý báu để học hỏi từ các chuyên gia trong ngành, trải nghiệm thực tế với các dịch vụ AWS mới và kết nối với cộng đồng công nghệ.\nTrong suốt quá trình thực tập, tôi đã tích cực tham gia 5 sự kiện nổi bật. Mỗi sự kiện là một trải nghiệm đáng nhớ, cung cấp những kiến thức mới mẻ, thú vị và hữu ích, giúp tôi định hình tư duy kỹ thuật và lộ trình sự nghiệp.\nSự kiện 1 Tên sự kiện: AWS GenAI \u0026amp; Data Revolution\nThời gian: 13:00, 24/10/2025\nĐịa điểm: Văn phòng AWS Việt Nam, TP. Hồ Chí Minh\nVai trò: Người tham dự\nSự kiện 2 Tên sự kiện: AI/ML/GenAI on AWS\nThời gian: 08:30, 15/11/2025\nĐịa điểm: Văn phòng AWS Việt Nam, TP. Hồ Chí Minh\nVai trò: Người tham dự\nSự kiện 3 Tên sự kiện: DevOps on AWS\nThời gian: 08:30, 17/11/2025\nĐịa điểm: Văn phòng AWS Việt Nam, TP. Hồ Chí Minh\nVai trò: Người tham dự\nSự kiện 4 Tên sự kiện: AWS Well-Architected Security Pillar\nThời gian: 08:30, 29/11/2025\nĐịa điểm: Văn phòng AWS Việt Nam, TP. Hồ Chí Minh\nVai trò: Người tham dự\nSự kiện 5 Tên sự kiện: Agentic AI: From Architecture to Implementation\nThời gian: 09:00, 02/12/2025 (Dự kiến)\nĐịa điểm: Văn phòng AWS Việt Nam, TP. Hồ Chí Minh\nVai trò: Người tham dự\n"},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/1-worklog/1.4-week4/","title":"Báo cáo công việc Tuần 4","tags":[],"description":"","content":"Mục tiêu Tuần 4: Triển khai tính sẵn sàng cao (High Availability - HA) và khả năng mở rộng (Scalability) cho ứng dụng web. Làm chủ cấu hình Application Load Balancer (ALB) và Auto Scaling Group (ASG). Thực hiện stress test để kiểm chứng khả năng tự động mở rộng. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tìm hiểu các loại Elastic Load Balancing (ELB): ALB vs NLB.\n- Tạo Target Groups và đăng ký targets.\n- Thực hành: Tạo một Application Load Balancer. 29/09/2025 29/09/2025 https://docs.aws.amazon.com/elasticloadbalancing/ 3 - Hiểu về Amazon Machine Image (AMI).\n- Thực hành: Tạo AMI tùy chỉnh từ Web Server (EC2) đã tạo ở Tuần 3 (đã cài sẵn LAMP stack). 30/09/2025 30/09/2025 https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html 4 - Học về Launch Templates và Auto Scaling Groups (ASG).\n- Cấu hình Scaling Policies (ví dụ: Target Tracking Scaling khi CPU \u0026gt; 50%). 01/10/2025 01/10/2025 https://docs.aws.amazon.com/autoscaling/ 5 - Tích hợp: Gắn Auto Scaling Group vào Application Load Balancer.\n- Đảm bảo cấu hình Health Check chính xác. 02/10/2025 02/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Stress Test: Giả lập lượng truy cập lớn vào ALB DNS.\n- Quan sát EC2 instances tự động scale out (thêm máy mới).\n- Kiểm chứng khả năng \u0026ldquo;Self-healing\u0026rdquo; bằng cách tắt thủ công một instance. 03/10/2025 03/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được trong Tuần 4: Tạo thành công một AMI (Amazon Machine Image) tùy chỉnh để triển khai ứng dụng nhanh chóng. Thiết kế và xây dựng kiến trúc có tính sẵn sàng cao sử dụng Application Load Balancer (ALB) để phân phối tải. Cấu hình Auto Scaling Group (ASG) đảm bảo ứng dụng có thể chịu được các mức tải khác nhau. Kiểm chứng tính đàn hồi (elasticity) của hệ thống: Scale-out: Tự động thêm server khi CPU tăng cao. High Availability: Tự động thay thế các server bị lỗi hoặc bị tắt. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/5-workshop/5.4-distribution/5.4.4-route53/","title":"Amazon Route 53","tags":[],"description":"","content":"Amazon Route 53 Cấu hình DNS để trỏ domain về CloudFront (Frontend) và ALB (Backend).\nCác bước thực hiện Truy cập Route 53 -\u0026gt; Hosted zones. Chọn domain của bạn. Route53 sẽ cấp 4 bản ghi NS, hãy cấu hình nó tại nơi đăng kí domain của bạn để có thể quản lí domain tại Route53. Quá trình này mất khoảng vài phút 1. Trỏ về Backend (ALB) Create record. Record name: api (ví dụ api.example.com). Record type: A. Bật Alias. Route traffic to: Alias to Application and Classic Load Balancer. Chọn Region và ALB của bạn. 2. Trỏ về Frontend (CloudFront) Create record. Record name: www hoặc để trống (root domain). Record type: A. Bật Alias. Route traffic to: Alias to CloudFront distribution. Chọn CloudFront distribution. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/4-eventparticipated/4.3-event3/","title":"Báo cáo sự kiện: DevOps on AWS","tags":[],"description":"","content":"Báo cáo tổng hợp: “Hội thảo DevOps on AWS” Mục tiêu sự kiện Hiểu về văn hóa DevOps, các nguyên tắc cốt lõi và các chỉ số đo lường hiệu quả (DORA metrics). Làm chủ bộ công cụ AWS Developer Tools để xây dựng quy trình CI/CD tự động. Học về Cơ sở hạ tầng dưới dạng mã (IaC) sử dụng AWS CloudFormation và CDK. Khám phá các dịch vụ Container (ECS, EKS, App Runner) và công cụ giám sát (CloudWatch, X-Ray). Diễn giả Đội ngũ Kiến trúc sư Giải pháp AWS (AWS Solutions Architects - Vietnam) Nội dung chính (Highlights) Tư duy DevOps \u0026amp; Dịch vụ CI/CD Chỉ số đo lường: Mở đầu bằng tầm quan trọng của các chỉ số DORA (Tần suất triển khai, Thời gian phục hồi, v.v.) để đánh giá độ trưởng thành của DevOps. Tự động hóa Pipeline: Đi sâu vào quy trình đầy đủ: Source: CodeCommit \u0026amp; chiến lược Git (Trunk-based vs GitFlow). Build \u0026amp; Test: Sử dụng CodeBuild để biên dịch và chạy unit tests. Deploy: Các chiến lược Blue/Green và Canary với CodeDeploy để giảm thiểu thời gian chết (downtime). Điều phối: Kết nối mọi thứ bằng CodePipeline. Cơ sở hạ tầng dưới dạng mã (IaC) CloudFormation vs CDK: So sánh rõ ràng giữa việc định nghĩa hạ tầng bằng template JSON/YAML (CloudFormation) và sử dụng ngôn ngữ lập trình quen thuộc như TypeScript/Python (CDK). Phát hiện sai lệch (Drift Detection): Cách phát hiện khi hạ tầng thực tế bị thay đổi so với định nghĩa trong mã. Dịch vụ Container Lựa chọn công cụ: Hướng dẫn khi nào nên dùng Amazon ECS (đơn giản, chuẩn AWS), Amazon EKS (chuẩn Kubernetes) hay App Runner (quản lý hoàn toàn/đơn giản nhất). Registry: Sử dụng Amazon ECR để lưu trữ image an toàn và quét lỗ hổng bảo mật. Giám sát \u0026amp; Khả năng quan sát (Observability) Tầm nhìn toàn diện (Full-stack): Không chỉ là logs. Đó là sự kết hợp giữa Metrics, Logs và Traces (dùng AWS X-Ray) để gỡ lỗi hiệu quả cho các microservices phân tán. Bài học rút ra (Key Takeaways) Tự động hóa là then chốt Triển khai thủ công rất dễ gây lỗi. Mục tiêu là tự động hóa mọi thứ từ cấp phát hạ tầng (IaC) đến triển khai mã nguồn (CI/CD). Hạ tầng bất biến (Immutable Infrastructure) Qua phần Container, tôi hiểu giá trị của hạ tầng bất biến—đóng gói ứng dụng và dependencies vào Docker container đảm bảo nó chạy giống hệt nhau ở mọi môi trường. Shift Left Kiểm thử và quét bảo mật nên được thực hiện sớm trong pipeline (tại bước CodeBuild/ECR), chứ không phải đợi sau khi đã deploy. Ứng dụng vào công việc Cải tiến Pipeline: Tôi sẽ thử áp dụng chiến lược deploy \u0026ldquo;Blue/Green\u0026rdquo; cho dự án thực tập hiện tại bằng CodeDeploy để đảm bảo zero downtime. Thử nghiệm AWS CDK: Thay vì thao tác trên console, tôi sẽ viết script CDK để khởi tạo VPC và EC2 cho bài tập tiếp theo. Kích hoạt X-Ray: Tôi dự định gắn AWS X-Ray vào ứng dụng để trực quan hóa bản đồ dịch vụ (service maps) và tìm điểm nghẽn về độ trễ. Trải nghiệm sự kiện Hội thảo \u0026ldquo;DevOps on AWS\u0026rdquo; kéo dài cả ngày mang lại kiến thức rất toàn diện và xâu chuỗi được nhiều vấn đề.\nTừ lý thuyết đến thực hành Sự chuyển tiếp từ lý thuyết DevOps Mindset buổi sáng sang thực hành cấu hình CI/CD Pipeline giúp tôi hiểu rõ tại sao cần dùng những công cụ này, chứ không chỉ là làm thế nào.\nSự rõ ràng về Container Tôi từng khá bối rối giữa ECS và EKS. Phần phân tích buổi chiều giúp tôi hiểu rõ: ECS dành cho sự điều phối \u0026ldquo;theo chuẩn AWS\u0026rdquo; còn EKS dành cho \u0026ldquo;chuẩn Kubernetes\u0026rdquo;.\nDemo trực quan Phần demo về Full-stack observability sử dụng CloudWatch và X-Ray thực sự mở mang tầm mắt. Việc nhìn thấy một request được truy vết từ Load Balancer xuống tận câu lệnh Database cho thấy sức mạnh của việc giám sát hiện đại.\nMột số hình ảnh tại sự kiện Tổng kết lại, sự kiện này đã trang bị bộ công cụ thiết yếu cho một Kỹ sư Cloud hiện đại: CI/CD, IaC, Containers và Monitoring.\n"},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/5-workshop/5.4-distribution/","title":"Distribution","tags":[],"description":"","content":"Phân phối nội dung Phần này giúp đưa ứng dụng đến người dùng cuối một cách bảo mật và hiệu năng cao.\nNội dung Certificate (ACM): Cấp phát chứng chỉ SSL/TLS miễn phí. Application Load Balancer (ALB): Cân bằng tải cho Backend (Spring Boot). CloudFront: CDN phân phối Frontend (ReactJS) và Static files (S3). Route 53: Quản lý DNS domain. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/4-eventparticipated/4.4-event4/","title":"Báo cáo sự kiện: AWS Security Pillar","tags":[],"description":"","content":"Báo cáo tổng hợp: “AWS Well-Architected Security Pillar” Mục tiêu sự kiện Nắm vững các nguyên tắc cốt lõi của Trụ cột Bảo mật: Đặc quyền tối thiểu (Least Privilege), Zero Trust và Phòng thủ chiều sâu (Defense in Depth). Hiểu kiến trúc IAM hiện đại và cách loại bỏ việc sử dụng thông tin xác thực dài hạn (long-term credentials). Học cách triển khai các lớp phát hiện và giám sát liên tục (GuardDuty, Security Hub). Đi sâu vào bảo vệ Hạ tầng/Dữ liệu và Tự động hóa ứng phó sự cố (Incident Response). Diễn giả Đội ngũ Kiến trúc sư Giải pháp AWS (Chuyên gia Bảo mật) Nội dung chính (Highlights) 1. Quản lý Định danh \u0026amp; Truy cập (IAM) Định danh là bức tường lửa mới: Phiên thảo luận nhấn mạnh việc chuyển dịch từ bảo mật dựa trên mạng sang bảo mật dựa trên định danh. Best Practices: Tránh dùng IAM User với key dài hạn. Thay vào đó, sử dụng IAM Identity Center cho SSO và các thông tin xác thực tạm thời qua Roles. Kiểm soát truy cập: Sử dụng SCPs (Service Control Policies) để quản trị đa tài khoản và Access Analyzer để kiểm tra chính sách. 2. Phát hiện \u0026amp; Giám sát (Detection) Tầm nhìn tập trung: Tích hợp CloudTrail (kiểm toán API) và VPC Flow Logs với AWS Security Hub để có một giao diện quản lý an ninh duy nhất. Detection-as-Code: Coi các quy tắc bảo mật và cảnh báo như mã nguồn để đảm bảo tính nhất quán giữa các môi trường. 3. Bảo vệ Hạ tầng \u0026amp; Dữ liệu Phòng thủ chiều sâu (Defense in Depth): Phân lớp các biện pháp kiểm soát: Mạng: Phân đoạn VPC, WAF, Shield và Network Firewall. Dữ liệu: Mã hóa khi lưu trữ (at-rest) và khi truyền tải (in-transit) sử dụng AWS KMS. Quản lý Secrets: Sử dụng AWS Secrets Manager để tự động xoay vòng (rotate) mật khẩu cơ sở dữ liệu thay vì hardcode trong ứng dụng. 4. Ứng phó sự cố (Incident Response - IR) Khái niệm \u0026ldquo;Playbook\u0026rdquo;: Định nghĩa các bước cụ thể cho các tình huống phổ biến như lộ IAM key hoặc lộ S3 bucket ra public. Tự động hóa: Sử dụng Lambda hoặc Step Functions để tự động cô lập EC2 bị nhiễm mã độc hoặc thu hồi quyền người dùng ngay khi phát hiện. Bài học rút ra (Key Takeaways) Kiến trúc Zero Trust Không bao giờ tin tưởng, luôn luôn xác minh. Mọi yêu cầu, dù là nội bộ hay bên ngoài, đều phải được xác thực và cấp quyền. Tự động hóa Bảo mật Tốc độ của con người không đủ để chống lại các mối đe dọa mạng. Các phản ứng bảo mật (như cô lập server) cần được tự động hóa bằng EventBridge và Lambda. Mô hình Trách nhiệm chung Ôn lại mô hình: AWS bảo mật \u0026ldquo;của đám mây\u0026rdquo; (phần cứng, hạ tầng toàn cầu), trong khi khách hàng bảo mật \u0026ldquo;trong đám mây\u0026rdquo; (dữ liệu, cấu hình, bản vá). Ứng dụng vào công việc Kiểm toán IAM Policies: Sử dụng IAM Access Analyzer để kiểm tra các policy đang cấp quyền quá rộng trong dự án hiện tại. Triển khai Secrets Manager: Loại bỏ tất cả các API key bị hardcode trong code và thay thế bằng việc gọi tới AWS Secrets Manager. Bật GuardDuty: Kích hoạt Amazon GuardDuty trong tài khoản thực tập để phát hiện các mối đe dọa tiềm ẩn. Trải nghiệm sự kiện Buổi workshop \u0026ldquo;AWS Well-Architected Security Pillar\u0026rdquo; đã cung cấp một khung tư duy mạch lạc về bảo mật.\nHọc tập có hệ thống Việc chia nhỏ bảo mật thành 5 trụ cột rõ ràng (IAM, Detection, Infra, Data, IR) giúp một chủ đề rộng lớn và phức tạp trở nên dễ quản lý và tiếp thu hơn.\nDemo thực tế hữu ích Phần demo trực tiếp về Validate IAM Policy và mô phỏng truy cập rất hữu ích. Nó chỉ ra cách xác minh quyền trước khi deploy, giúp tránh các lỗi \u0026ldquo;Access Denied\u0026rdquo; khi lên môi trường production.\nTính thực tiễn tại Việt Nam Phần thảo luận về \u0026ldquo;Top các mối đe dọa trong môi trường cloud tại Việt Nam\u0026rdquo; và các sai lầm thường gặp giúp tôi có cái nhìn thực tế về bối cảnh an ninh mạng mà tôi sẽ đối mặt trong công việc.\nMột số hình ảnh tại sự kiện Thêm ảnh sự kiện của bạn vào đây\nTổng kết lại, sự kiện này đã thay đổi tư duy của tôi từ \u0026ldquo;Bảo mật là rào cản\u0026rdquo; sang \u0026ldquo;Bảo mật là yếu tố then chốt\u0026rdquo; (enabler) cho việc phát triển ứng dụng hiện đại.\n"},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/1-worklog/1.5-week5/","title":"Báo cáo công việc Tuần 5","tags":[],"description":"","content":"Mục tiêu Tuần 5: Nắm vững các khái niệm về Quản lý Định danh và Truy cập (IAM). Triển khai \u0026ldquo;Nguyên tắc đặc quyền tối thiểu\u0026rdquo; (Principle of Least Privilege) cho người dùng và dịch vụ. Bảo mật tài nguyên AWS bằng cách sử dụng IAM Roles thay vì lưu trữ key dài hạn. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Học các thành phần cốt lõi IAM: Users, Groups, Policies (Cấu trúc JSON).\n- Thực hành: Tạo IAM Groups (Dev, Admin) và gán các managed policies. 06/10/2025 06/10/2025 https://docs.aws.amazon.com/iam/ 3 - Tìm hiểu về IAM Roles và Service-Linked Roles.\n- Kịch bản: Tạo một IAM Role cho phép EC2 truy cập S3 buckets (Read/Write) mà không cần Access Keys. 07/10/2025 07/10/2025 https://docs.aws.amazon.com/iam/ 4 - Thực hành: Gắn IAM Role đã tạo vào một EC2 instance đang chạy.\n- SSH vào EC2 và kiểm tra quyền truy cập S3 qua AWS CLI (aws s3 ls). 08/10/2025 08/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tăng cường bảo mật tài khoản:\n- Bật MFA (Multi-Factor Authentication) cho tài khoản Root và IAM users.\n- Cấu hình Password Policy (độ dài, độ phức tạp). 09/10/2025 09/10/2025 https://docs.aws.amazon.com/iam/ 6 - Ôn tập Mô hình Trách nhiệm chung (Shared Responsibility Model).\n- Khám phá AWS CloudTrail để kiểm toán các lệnh gọi API (ai đã làm gì, khi nào). 10/10/2025 10/10/2025 https://aws.amazon.com/compliance/shared-responsibility-model/ Kết quả đạt được trong Tuần 5: Hiểu sâu về Mô hình Trách nhiệm chung của AWS và logic hoạt động của IAM. Triển khai các ranh giới phân quyền chặt chẽ bằng cách sử dụng IAM Policies và Groups. Thay thế thành công việc sử dụng hard-coded credentials (Access/Secret Keys) bằng IAM Roles an toàn hơn cho việc truy cập dịch vụ từ EC2. Nâng cao bảo mật tài khoản bằng cách bắt buộc sử dụng MFA và chính sách mật khẩu mạnh. Xác minh giao tiếp an toàn giữa các dịch vụ (EC2 gọi sang S3) mà không để lộ thông tin xác thực. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/5-workshop/5.5-deploy/","title":"CI/CD","tags":[],"description":"","content":"Tích hợp và Triển khai liên tục (CI/CD) Sử dụng GitLab CI để tự động hóa quy trình build và deploy ứng dụng lên AWS.\nNội dung SSH vào EC2 instance để cài đặt những ứng dụng cần thiết GitLab Runner: Cấu hình runner trên EC2 (hoặc dùng Shared Runner). Pipeline: Định nghĩa file .gitlab-ci.yml. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/5-workshop/","title":"Triển khai hệ thống","tags":[],"description":"","content":"Triển khai hệ thống Auction trên AWS Chào mừng bạn đến với workshop triển khai hệ thống đấu giá trực tuyến trên nền tảng AWS. Trong workshop này, chúng ta sẽ cùng nhau xây dựng từng thành phần của hệ thống dựa trên kiến trúc đã đề xuất.\nMục tiêu Hoàn thành việc cài đặt và cấu hình các dịch vụ AWS cần thiết để vận hành hệ thống Auction System.\nKiến trúc Chúng ta sẽ bám sát kiến trúc sau:\nCác bước thực hiện Chuẩn bị (Preparation): Thiết lập VPC, IAM Role. Cơ sở dữ liệu \u0026amp; Lưu trữ (Database \u0026amp; Storage): Cấu hình RDS, ElastiCache, S3. Tính toán (Compute): Cài đặt và cấu hình EC2. Phân phối (Distribution): Cấu hình Load Balancer, CloudFront, Route 53. CI/CD: Thiết lập quy trình triển khai tự động với GitLab CI. Dọn dẹp (Clean up): Xóa tài nguyên sau khi hoàn thành. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/1-worklog/1.6-week6/","title":"Báo cáo công việc Tuần 6","tags":[],"description":"","content":"Mục tiêu Tuần 6: Hiểu về Amazon Simple Email Service (SES) và các trường hợp sử dụng (Giao dịch vs Tiếp thị). Xác minh danh tính (Email/Domain) và hiểu về các giới hạn của chế độ Sandbox. Gửi email bằng lập trình sử dụng AWS SDK (Boto3 với Python) trên EC2. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Giới thiệu về Amazon SES.\n- Thực hành: Xác minh một Email Identity (Người gửi và Người nhận) trong SES Console.\n- Tìm hiểu khái niệm chế độ \u0026ldquo;SES Sandbox\u0026rdquo;. 13/10/2025 13/10/2025 https://docs.aws.amazon.com/ses/ 3 - Cấu hình thông tin xác thực SMTP cho SES.\n- Tìm hiểu quy trình yêu cầu truy cập Production (thoát khỏi Sandbox). 14/10/2025 14/10/2025 https://docs.aws.amazon.com/ses/ 4 - Lập trình: Viết một script Python đơn giản sử dụng thư viện boto3 để gửi email test thông qua SES API.\n- Xử lý các ngoại lệ lỗi (ví dụ: MessageRejected). 15/10/2025 15/10/2025 https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ses.html 5 - Tích hợp: Triển khai script Python lên một EC2 instance.\n- Cấu hình IAM Role cho EC2 để cấp quyền ses:SendEmail (thay vì dùng SMTP credentials cố định). 16/10/2025 16/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Kiểm thử: Chạy script trên EC2 để kích hoạt thông báo email tự động.\n- Giám sát thống kê gửi nhận trong SES Console (Tỷ lệ gửi thành công, Bounce rate). 17/10/2025 17/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được trong Tuần 6: Cấu hình thành công môi trường Amazon SES và xác minh các danh tính email. Hiểu và áp dụng các phương pháp bảo mật tốt nhất bằng cách sử dụng IAM Roles cho EC2 để cấp quyền gửi email. Phát triển được script tự động hóa bằng Python sử dụng AWS SDK (Boto3) để tương tác với dịch vụ AWS. Tích hợp khả năng thông báo qua email vào hạ tầng, cho phép gửi cảnh báo tự động. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/4-eventparticipated/4.5-event5/","title":"Báo cáo sự kiện: Agentic AI Journey","tags":[],"description":"","content":"Báo cáo tổng hợp: “Agentic AI: Từ Kiến trúc đến Triển khai” Mục tiêu sự kiện Hiểu các khái niệm cốt lõi của Agentic AI (AI hành động) và AWS Bedrock Agents. Khám phá các trường hợp sử dụng thực tế (Use Cases) để xây dựng luồng công việc tự động (Agentic Workflow). Đi sâu vào kỹ thuật Điều phối Agent và Tối ưu hóa ngữ cảnh (mức độ chuyên sâu L300). Trải nghiệm thực hành: Xây dựng một Agent sử dụng CloudThinker và AWS Bedrock. Diễn giả Nguyễn Gia Hưng – Trưởng bộ phận Kiến trúc sư Giải pháp Kiên Nguyễn – Kiến trúc sư Giải pháp (AWS) Việt Phạm – Founder \u0026amp; CEO Thắng Tôn – Co-founder \u0026amp; COO (CloudThinker) Henry Bùi – Giám đốc Kỹ thuật (CloudThinker) Kha Vân – Technical Lead/Người hướng dẫn Nội dung chính (Highlights) AWS Bedrock Agent Core Khái niệm: Chuyển dịch từ các \u0026ldquo;Chatbot\u0026rdquo; thụ động sang các \u0026ldquo;Agent\u0026rdquo; chủ động có khả năng thực thi các tác vụ đa bước. Thành phần: Giải phẫu cấu trúc của một Agent: Foundation Model (Bộ não) + Action Groups (Công cụ/API) + Knowledge Bases (RAG). Cơ chế: Cách Bedrock Agents chia nhỏ một yêu cầu phức tạp của người dùng thành chuỗi các bước logic (Chain-of-Thought) và thực thi chúng qua Lambda functions. Ứng dụng thực tế \u0026amp; CloudThinker Use Cases: Tạo ra các quy trình nơi AI tự động xử lý công việc kinh doanh (đặt lịch, xử lý đơn hàng, phân tích dữ liệu) mà không cần con người can thiệp. Điều phối (L300 Deep Dive): Anh Henry Bùi chia sẻ các kỹ thuật nâng cao về quản lý tương tác phức tạp giữa các agent. Trọng tâm là Tối ưu hóa ngữ cảnh (Context Optimization)—đảm bảo AI giữ được thông tin quan trọng trong các hội thoại dài mà không bị tràn bộ nhớ (token limits) hoặc mất tập trung. Nền tảng CloudThinker: Giới thiệu framework chuyên dụng giúp đơn giản hóa việc điều phối các luồng agent phức tạp trên nền tảng AWS. Workshop thực hành: CloudThinker Hack Thực chiến: Dưới sự hướng dẫn của anh Kha Vân, người tham dự đã thiết lập môi trường và triển khai một agent hoạt động thực tế. Tích hợp: Kết nối agent với các công cụ bên ngoài và quan sát cách nó suy luận để giải quyết vấn đề theo thời gian thực. Bài học rút ra (Key Takeaways) Bước chuyển mình sang \u0026ldquo;Agency\u0026rdquo; Tương lai của AI không chỉ là tạo sinh văn bản, mà là hành động. \u0026ldquo;Agentic AI\u0026rdquo; là biên giới tiếp theo nơi các mô hình trở thành người ra quyết định. Ngữ cảnh là Vua (Context is King) Trong các luồng công việc phức tạp, quản lý \u0026ldquo;Trạng thái\u0026rdquo; (State) và \u0026ldquo;Ngữ cảnh\u0026rdquo; là thách thức lớn nhất. Các kỹ thuật tối ưu hóa (như tóm tắt ngữ cảnh hoặc lưu giữ chọn lọc) là yếu tố sống còn cho các agent chạy production. Sự phức tạp trong điều phối Xây dựng một agent thì dễ; làm cho nhiều agent phối hợp nhịp nhàng đòi hỏi một lớp điều phối mạnh mẽ (điều mà các công cụ như CloudThinker giải quyết). Ứng dụng vào công việc Thử nghiệm Action Groups: Tôi sẽ thử thêm một \u0026ldquo;Action Group\u0026rdquo; đơn giản vào dự án Bedrock của mình (ví dụ: Lambda function truy vấn database) để biến chatbot hiện tại thành một basic agent. Nghiên cứu quản lý ngữ cảnh: Tìm hiểu sâu hơn về cách tối ưu context cho các tác vụ dài hơi, dựa trên kiến thức từ phiên L300. Kiểm thử hành vi Agent: Áp dụng tư duy kiểm thử để đánh giá xem agent có thực hiện đúng hành động (action) hay không trước khi deploy. Trải nghiệm sự kiện Sự kiện \u0026ldquo;Agentic AI\u0026rdquo; là sự kết hợp hoàn hảo giữa lý thuyết và thực hành.\nChiều sâu kỹ thuật (L300) Tôi đặc biệt đánh giá cao phiên chia sẻ L300 của anh Henry Bùi. Thông thường các sự kiện chỉ dừng ở mức tổng quan, nhưng phiên này đi sâu vào thách thức kỹ thuật của việc tối ưu hóa Context, mang lại kiến thức kiến trúc rất giá trị.\nPhần \u0026ldquo;Hack\u0026rdquo; thực tế Phiên thực hành cuối giờ rất năng lượng và hữu ích. Việc nhìn thấy agent do mình cấu hình thực sự thực thi một tác vụ (thay vì chỉ trả lời bằng chữ) là một khoảnh khắc \u0026ldquo;vỡ lẽ\u0026rdquo; về sức mạnh của hệ sinh thái Bedrock.\nNetworking Thời gian ăn trưa và giao lưu giúp tôi có cơ hội thảo luận với đội ngũ CloudThinker về vấn đề độ trễ (latency) trong các luồng agent, thu được nhiều mẹo thực tế cho dự án cá nhân.\nMột số hình ảnh tại sự kiện Thêm ảnh sự kiện của bạn vào đây\nTổng kết lại, sự kiện đã thu hẹp khoảng cách giữa \u0026ldquo;sự hào nhoáng\u0026rdquo; về AI Agents và \u0026ldquo;cách làm\u0026rdquo; thực tế để xây dựng chúng trên AWS.\n"},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/5-workshop/5.6-cleanup/","title":"Dọn dẹp tài nguyên","tags":[],"description":"","content":"Dọn dẹp tài nguyên (Clean Up) Để tránh phát sinh chi phí không mong muốn sau khi hoàn thành workshop, hãy xóa các tài nguyên theo thứ tự sau:\nThứ tự xóa EC2: Terminate các instance. RDS \u0026amp; ElastiCache: Delete database và cache cluster. Xóa cả Subnet Group và Snapshots. Load Balancer \u0026amp; Target Group: Delete ALB sau đó đến Target Group. CloudFront: Disable distribution, đợi deploy xong rồi Delete. S3: Empty bucket (xóa hết object) sau đó Delete bucket. NAT Gateway \u0026amp; Elastic IP: Delete NAT Gateway -\u0026gt; Release Elastic IP. VPC: Delete VPC (sẽ tự động xóa Subnets, Internet Gateway, Route Table, Security Group liên quan). Lưu ý: Kiểm tra kỹ Billing Dashboard vào ngày hôm sau để chắc chắn không còn chi phí phát sinh.\n"},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/6-self-evaluation/","title":"Tự đánh giá bản thân","tags":[],"description":"","content":"Trong quá trình thực tập tại First Cloud Journey (FCJ) từ ngày 08/09/2025 đến 28/11/2025, em đã có cơ hội học tập, thực hành và áp dụng những kiến thức đã học ở trường vào môi trường làm việc thực tế.\nEm đã tham gia vào lộ trình DevOps \u0026amp; Cloud Computing, qua đó cải thiện các kỹ năng về dịch vụ AWS (EC2, S3, VPC), Infrastructure as Code (Terraform), quy trình CI/CD và Containerization.\nVề thái độ làm việc, em luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ quy định nơi làm việc và tích cực tương tác với đồng nghiệp để nâng cao hiệu quả công việc. Tuy nhiên, em nhận thấy bản thân vẫn còn nhiều thiếu sót cần khắc phục về kỷ luật và kỹ năng mềm.\nĐể nhìn nhận một cách khách quan về quá trình thực tập, em xin tự đánh giá bản thân dựa trên các tiêu chí sau (Tự chấm: 6.5/10):\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức \u0026amp; Kỹ năng chuyên môn Hiểu biết về lĩnh vực, vận dụng vào thực tế, thành thạo công cụ ☐ ✅ ☐ 2 Khả năng học hỏi Khả năng tiếp thu kiến thức mới và học nhanh ☐ ✅ ☐ 3 Sự chủ động Tự giác tìm việc, không đợi nhắc nhở ☐ ✅ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ☐ ✅ ☐ 5 Tính kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tư duy cầu tiến Sẵn sàng nhận phản hồi và sửa đổi bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng và báo cáo công việc rõ ràng ☐ ☐ ✅ 8 Làm việc nhóm Phối hợp hiệu quả với đồng nghiệp ☐ ✅ ☐ 9 Tác phong chuyên nghiệp Tôn trọng đồng nghiệp, đối tác và môi trường làm việc ✅ ☐ ☐ 10 Kỹ năng giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ☐ ✅ 11 Đóng góp cho dự án/nhóm Hiệu quả công việc, ý tưởng mới ☐ ✅ ☐ 12 Tổng quan Đánh giá chung cho cả kỳ thực tập ☐ ✅ ☐ Điểm cần cải thiện Kỷ luật: Cần tăng cường tính tự giác và tuân thủ nghiêm ngặt các quy định về giờ giấc và thời hạn báo cáo của tổ chức. Tư duy giải quyết vấn đề: Cần cải thiện khả năng tư duy độc lập khi gặp lỗi kỹ thuật, học cách tự troubleshoot kỹ càng hơn trước khi nhờ hỗ trợ. Giao tiếp: Nâng cao kỹ năng giao tiếp trong môi trường chuyên nghiệp, đặc biệt là khả năng trình bày vấn đề kỹ thuật một cách gãy gọn, dễ hiểu. Sự tập trung: Cần duy trì sự tập trung cao độ hơn trong giờ làm việc để tối ưu hóa năng suất. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/1-worklog/1.7-week7/","title":"Báo cáo công việc Tuần 7","tags":[],"description":"","content":"Mục tiêu Tuần 7: Chuyển đổi từ cấu hình thủ công (\u0026ldquo;ClickOps\u0026rdquo;) sang Hạ tầng dưới dạng mã (IaC). Học các kiến thức cơ bản về Terraform: Providers, Resources, Variables, và State. Tự động hóa việc khởi tạo tài nguyên VPC và EC2 bằng Terraform. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Giới thiệu về khái niệm IaC.\n- Cài đặt Terraform và cấu hình AWS credentials trên máy cá nhân.\n- Học cú pháp HCL (HashiCorp Configuration Language). 20/10/2025 20/10/2025 https://developer.hashicorp.com/terraform/intro 3 - Coding: Viết file vpc.tf để tạo VPC, Subnet, Internet Gateway, và Route Table.\n- Tìm hiểu về Terraform Providers (aws). 21/10/2025 21/10/2025 https://registry.terraform.io/providers/hashicorp/aws/latest/docs 4 - Coding: Viết file main.tf để khởi chạy EC2 instance bên trong VPC đã tạo.\n- Sử dụng variables.tf để tham số hóa các giá trị (Region, AMI ID, Instance Type). 22/10/2025 22/10/2025 https://developer.hashicorp.com/terraform/language 5 - Hiểu quy trình làm việc Terraform: init, plan, apply, destroy.\n- Tìm hiểu về terraform.tfstate và cách quản lý file trạng thái. 23/10/2025 23/10/2025 https://developer.hashicorp.com/terraform/cli/commands 6 - Mini-Project: Tái tạo kiến trúc Tuần 2 (VPC + EC2) hoàn toàn bằng mã Terraform.\n- Kiểm tra việc triển khai qua AWS Console và sau đó hủy tài nguyên chỉ bằng một lệnh. 24/10/2025 24/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được trong Tuần 7: Chuyển đổi thành công từ thao tác thủ công trên Console sang quản lý hạ tầng bằng mã Terraform. Nắm vững quy trình làm việc cốt lõi của Terraform (init -\u0026gt; plan -\u0026gt; apply -\u0026gt; destroy). Tạo được mã nguồn hạ tầng có khả năng tái sử dụng nhờ Variables. Triển khai môi trường VPC và EC2 hoàn chỉnh chỉ trong vài phút bằng một dòng lệnh. Hiểu được tầm quan trọng của việc quản lý State (trạng thái) trong IaC. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/7-feedback/","title":"Chia sẻ và Đóng góp ý kiến","tags":[],"description":"","content":" Dưới đây là những chia sẻ thẳng thắn của em sau 12 tuần thực tập. Những ý kiến này dựa trên trải nghiệm cá nhân của một sinh viên đang trong quá trình chuyển đổi kiến thức từ nhà trường sang thực tế doanh nghiệp.\nĐánh giá tổng quan 1. Môi trường làm việc Môi trường tại FCJ mang tính kỹ thuật cao và nhịp độ nhanh. Thay vì \u0026ldquo;cầm tay chỉ việc\u0026rdquo;, môi trường này thúc đẩy thực tập sinh phải tự lập và chủ động nghiên cứu. Ban đầu em cảm thấy hơi choáng ngợp (overwhelmed), nhưng chính áp lực chuyên nghiệp này đã giúp em thích nghi nhanh với tiêu chuẩn ngành. Đây là nơi dành cho những ai thực sự muốn \u0026ldquo;làm thật\u0026rdquo; chứ không chỉ đến để quan sát.\n2. Sự hỗ trợ từ Mentor / Team Admin Các Mentor khá nghiêm khắc nhưng công tâm. Khi em gặp lỗi (ví dụ như lỗi Terraform state hay pipeline bị fail), thay vì đưa ngay đáp án, Mentor hướng dẫn em cách đọc log và tư duy tìm nguyên nhân gốc rễ (Root Cause Analysis). Cách làm này tuy mất thời gian lúc đầu nhưng cực kỳ hiệu quả trong việc rèn luyện tư duy troubleshooting. Team Admin hỗ trợ rất nhanh trong việc cấp quyền và tài khoản AWS.\n3. Mức độ phù hợp với chuyên ngành Khoảng cách giữa lý thuyết đại học và thực tế làm việc là khá lớn. Trong khi nhà trường cung cấp tư duy lập trình nền tảng, kỳ thực tập này đã lấp đầy những lỗ hổng về Hạ tầng, Mạng và Chiến lược triển khai. Các tác vụ liên quan đến AWS Services và quy trình DevOps là hoàn toàn mới mẻ và sát sườn với định hướng nghề nghiệp Kỹ sư Cloud mà em đang theo đuổi.\n4. Cơ hội học hỏi và phát triển kỹ năng Ngoài kỹ năng cứng (AWS, Docker, IaC), bài học giá trị nhất em nhận được là \u0026ldquo;Tư duy hệ thống\u0026rdquo; (System Thinking). Em học được cách nhìn phần mềm không chỉ là những dòng code, mà là một vòng đời trọn vẹn từ phát triển, vận hành đến giám sát. Các buổi workshop kỹ thuật hàng tuần (GenAI, Security) là những giá trị gia tăng chất lượng giúp mở rộng tầm nhìn.\n5. Văn hóa công ty và Tinh thần đội nhóm Văn hóa \u0026ldquo;Chia sẻ kiến thức\u0026rdquo; (Knowledge Sharing) ở đây rất mạnh mẽ. Không có câu hỏi nào bị coi là \u0026ldquo;ngớ ngẩn\u0026rdquo; nếu mình đã thực sự cố gắng tự tìm hiểu trước đó. Em đánh giá cao sự minh bạch trong các thảo luận kỹ thuật, nơi ý kiến của thực tập sinh cũng được lắng nghe trong các buổi review kiến trúc.\n6. Chính sách / Phúc lợi thực tập Lộ trình thực tập được xây dựng bài bản theo từng tuần, điều này khá hiếm thấy ở các nơi khác. Trợ cấp thực tập công bằng và thời gian làm việc linh hoạt giúp em cân đối được với việc hoàn thành đồ án tốt nghiệp ở trường.\nCâu hỏi bổ sung Điều gì làm bạn hài lòng nhất trong kỳ thực tập? Khoảnh khắc em tự tay xây dựng thành công một pipeline CI/CD tự động hoàn toàn, triển khai code lên EC2 mà không cần can thiệp thủ công (Tuần 8). Đó là kết quả hữu hình kết nối tất cả những khái niệm rời rạc mà em đã học.\nTheo bạn, công ty nên cải thiện điều gì cho các khóa thực tập sau? Em đề xuất nên có thêm các buổi Code Review chuyên sâu hơn dành riêng cho thực tập sinh. Đôi khi code của em \u0026ldquo;chạy được\u0026rdquo;, nhưng em không chắc nó đã tuân theo best practices hay tối ưu về chi phí/bảo mật chưa. Việc nhận được feedback chi tiết về chất lượng code sẽ giúp chúng em tiến bộ nhanh hơn.\nNếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Tại sao? Chắc chắn là có. Tuy nhiên em sẽ nói rõ trước: Em chỉ giới thiệu FCJ cho những bạn thực sự chủ động và có tính kỷ luật cao. Đây không phải là nơi dành cho những người học thụ động, nhưng là bệ phóng tuyệt vời cho những ai muốn trở thành Cloud Engineer nghiêm túc.\nĐề xuất và Mong muốn Đề xuất: Sẽ rất tuyệt nếu có một buổi \u0026ldquo;Phỏng vấn thử\u0026rdquo; (Mock Interview) vào cuối kỳ thực tập để giúp chúng em chuẩn bị tâm lý cho việc xin việc chính thức. Mong muốn: Em hy vọng được giữ kết nối với cộng đồng FCJ và rất mong được cân nhắc cho vị trí Fresher nếu công ty có nhu cầu tuyển dụng. Lời kết: Cảm ơn đội ngũ FCJ vì 3 tháng đầy thử thách nhưng rất đáng giá. Những tiêu chuẩn khắt khe ở đây đã giúp em trở thành một kỹ sư tốt hơn. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/1-worklog/1.8-week8/","title":"Báo cáo công việc Tuần 8","tags":[],"description":"","content":"Mục tiêu Tuần 8: Hiểu về văn hóa DevOps và khái niệm Tích hợp liên tục/Triển khai liên tục (CI/CD). Làm quen với bộ công cụ AWS Developer Tools (CodeCommit, CodeBuild, CodeDeploy, CodePipeline). Xây dựng một pipeline tự động hoàn toàn để triển khai thay đổi code lên EC2. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Giới thiệu về CI/CD pipelines.\n- Tạo Git repository trên AWS CodeCommit (hoặc kết nối GitHub).\n- Push source code web mẫu lên repository. 27/10/2025 27/10/2025 https://docs.aws.amazon.com/codecommit/ 3 - Cấu hình AWS CodeBuild:\n- Tạo file buildspec.yml để định nghĩa lệnh build (ví dụ: cài dependencies, chạy test).\n- Chạy thử một bản build thủ công. 28/10/2025 28/10/2025 https://docs.aws.amazon.com/codebuild/ 4 - Cấu hình AWS CodeDeploy:\n- Tạo file appspec.yml để định nghĩa hướng dẫn deploy.\n- Cài đặt CodeDeploy Agent trên EC2 đích. 29/10/2025 29/10/2025 https://docs.aws.amazon.com/codedeploy/ 5 - Tích hợp: Tạo Pipeline trong AWS CodePipeline.\n- Liên kết các giai đoạn: Source (CodeCommit) -\u0026gt; Build (CodeBuild) -\u0026gt; Deploy (CodeDeploy). 30/10/2025 30/10/2025 https://docs.aws.amazon.com/codepipeline/ 6 - Kiểm thử: Push một thay đổi code (ví dụ: đổi text trang web) lên repo.\n- Quan sát pipeline tự động kích hoạt và cập nhật server mà không cần can thiệp thủ công. 31/10/2025 31/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được trong Tuần 8: Có được hiểu biết thực tế về quy trình làm việc CI/CD trên AWS. Thiết lập thành công kho quản lý mã nguồn sử dụng AWS CodeCommit. Tự động hóa quy trình build bằng CodeBuild và deploy bằng CodeDeploy. Xây dựng một pipeline CI/CD hoàn chỉnh bằng AWS CodePipeline. Giảm đáng kể thời gian triển khai và lỗi do con người nhờ tự động hóa quy trình release. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/1-worklog/1.9-week9/","title":"Báo cáo công việc Tuần 9","tags":[],"description":"","content":"Mục tiêu Tuần 9: Hiểu về công nghệ Containerization và Docker. Học cách viết Dockerfile để đóng gói ứng dụng. Sử dụng Amazon Elastic Container Registry (ECR) để lưu trữ và quản lý Docker images. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Giới thiệu về Containers so với Máy ảo (VM).\n- Cài đặt Docker Engine trên EC2 instance (hoặc máy cá nhân).\n- Học các lệnh Docker cơ bản (run, ps, images, stop). 03/11/2025 03/11/2025 https://docs.docker.com/get-started/ 3 - Thực hành: Viết Dockerfile cho một ứng dụng web đơn giản (Python/Node.js).\n- Build Docker image trên máy local. 04/11/2025 04/11/2025 https://docs.docker.com/engine/reference/builder/ 4 - Giới thiệu về Amazon ECR.\n- Tạo một private repository trong Amazon ECR.\n- Cấu hình AWS CLI để xác thực Docker với ECR. 05/11/2025 05/11/2025 https://docs.aws.amazon.com/AmazonECR/ 5 - Thực hành: Gắn thẻ (Tag) cho Docker image và đẩy (Push) lên Amazon ECR repository.\n- Kiểm tra image trên AWS Console. 06/11/2025 06/11/2025 https://docs.aws.amazon.com/AmazonECR/ 6 - Triển khai: Khởi chạy một EC2 instance mới.\n- Kéo (Pull) image từ ECR về và chạy container.\n- Kiểm tra ứng dụng hoạt động bình thường. 07/11/2025 07/11/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được trong Tuần 9: Hiểu rõ lợi ích của container hóa so với ảo hóa truyền thống. Đóng gói thành công ứng dụng cũ bằng Docker (viết Dockerfile tối ưu). Nắm vững quy trình build, tag và push image lên registry. Sử dụng Amazon ECR làm nơi lưu trữ Docker image an toàn và riêng tư. Triển khai ứng dụng từ container image, đảm bảo tính nhất quán giữa các môi trường. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/1-worklog/1.10-week10/","title":"Báo cáo công việc Tuần 10","tags":[],"description":"","content":"Mục tiêu Tuần 10: Khám phá điện toán Serverless và kiến trúc hướng sự kiện (Event-driven). Xây dựng một RESTful API sử dụng Amazon API Gateway và AWS Lambda. Tích hợp các hàm Serverless với các dịch vụ AWS khác (như SES từ Tuần 6). Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Giới thiệu về Serverless: Các khái niệm AWS Lambda (Triggers, Runtimes, Layers).\n- Thực hành: Tạo hàm Lambda \u0026ldquo;Hello World\u0026rdquo; đơn giản (Python/Node.js). 10/11/2025 10/11/2025 https://docs.aws.amazon.com/lambda/ 3 - Test Lambda với các event test tùy chỉnh trong Console.\n- Tìm hiểu về IAM Roles cho Lambda (Execution Role). 11/11/2025 11/11/2025 https://docs.aws.amazon.com/lambda/ 4 - Giới thiệu về Amazon API Gateway.\n- Thực hành: Tạo một REST API.\n- Tạo Resources và Methods (GET/POST). 12/11/2025 12/11/2025 https://docs.aws.amazon.com/apigateway/ 5 - Tích hợp: Kết nối API Gateway với hàm Lambda (Lambda Proxy Integration).\n- Triển khai (Deploy) API ra một Stage (dev/prod). 13/11/2025 13/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành nâng cao: Chuyển đổi script gửi email (Tuần 6) lên chạy trên Lambda.\n- Kích hoạt hàm Lambda thông qua việc gọi API để gửi email tự động. 14/11/2025 14/11/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được trong Tuần 10: Triển khai code thành công mà không cần khởi tạo hay quản lý máy chủ (Serverless). Tạo được một API public endpoint có khả năng mở rộng bằng Amazon API Gateway. Kết hợp Serverless (Lambda) với SES để tạo hệ thống thông báo email hướng sự kiện. Hiểu rõ lợi ích chi phí của mô hình \u0026ldquo;Dùng bao nhiêu trả bấy nhiêu\u0026rdquo; trong Serverless. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/1-worklog/1.11-week11/","title":"Báo cáo công việc Tuần 11","tags":[],"description":"","content":"Mục tiêu Tuần 11: Triển khai khả năng quan sát (observability) cho hạ tầng AWS. Cấu hình CloudWatch Alarms để phát hiện sự cố chủ động. Tập trung logs và trực quan hóa các chỉ số trên Dashboards. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Khám phá các khái niệm Amazon CloudWatch: Namespaces, Metrics, Dimensions.\n- Kiểm tra các chỉ số EC2 tiêu chuẩn (CPU, Status Checks, Network). 17/11/2025 17/11/2025 https://docs.aws.amazon.com/cloudwatch/ 3 - Thực hành: Tạo một CloudWatch Alarm.\n- Điều kiện: Gửi email thông báo (qua SNS topic) nếu CPU Utilization \u0026gt; 80% trong 5 phút. 18/11/2025 18/11/2025 https://docs.aws.amazon.com/cloudwatch/ 4 - Tìm hiểu về CloudWatch Logs.\n- Cài đặt và cấu hình Unified CloudWatch Agent trên EC2 để đẩy logs hệ điều hành (syslog/messages) lên CloudWatch. 19/11/2025 19/11/2025 https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html 5 - Cấu hình Custom Metrics: Giám sát dung lượng RAM và Ổ cứng (Disk Space) - các chỉ số không có sẵn mặc định. 20/11/2025 20/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Dashboarding: Tạo một CloudWatch Dashboard tập trung.\n- Thêm các widget hiển thị CPU, Memory của EC2, lượng gọi API Gateway, và lỗi Lambda. 21/11/2025 21/11/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được trong Tuần 11: Thiết lập hệ thống giám sát chủ động cho các thành phần hạ tầng quan trọng. Cấu hình cảnh báo tự động (Alarms + SNS) giúp giảm thời gian phản hồi sự cố. Có được cái nhìn sâu hơn vào hiệu suất nội tại của hệ thống (RAM/Disk) nhờ CloudWatch Agent. Xây dựng Dashboard vận hành chuyên nghiệp để trực quan hóa sức khỏe hệ thống theo thời gian thực. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/1-worklog/1.12-week12/","title":"Báo cáo công việc Tuần 12","tags":[],"description":"","content":"Mục tiêu Tuần 12: Tổng hợp toàn bộ kiến thức và dự án đã làm thành báo cáo cuối khóa. Rà soát và tối ưu hóa các tài nguyên đã tạo. Dọn dẹp môi trường AWS để tránh phát sinh chi phí ngoài ý muốn (Quản lý chi phí). Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Rà soát: Kiểm kê tất cả tài nguyên đang hoạt động ở mọi regions (EC2, RDS, NAT Gateways, Elastic IPs, ALBs).\n- Xác định các tài nguyên không còn cần thiết. 24/11/2025 24/11/2025 AWS Billing Dashboard 3 - Dọn dẹp: Terminate EC2 instances, xóa RDS snapshots, release Elastic IPs, và xóa NAT Gateways để dừng tính phí.\n- Chỉ giữ lại các tài nguyên thuộc Free Tier nếu cần thiết. 25/11/2025 25/11/2025 AWS Billing Dashboard 4 - Tài liệu hóa: Hoàn thiện \u0026ldquo;Báo cáo Thực tập Cuối khóa\u0026rdquo; (Dự án Hugo).\n- Tập hợp lại tất cả các sơ đồ kiến trúc đã vẽ trong suốt 12 tuần. 26/11/2025 26/11/2025 5 - Chuẩn bị slide thuyết trình cho buổi bảo vệ/tổng kết thực tập.\n- Chạy thử demo các dự án chính (CI/CD Pipeline, Serverless API). 27/11/2025 27/11/2025 6 - Tự đánh giá về quá trình thực tập.\n- Nộp worklog và báo cáo cuối cùng cho mentor/người hướng dẫn.\n- Chính thức hoàn thành lộ trình 12 tuần. 28/11/2025 28/11/2025 Kết quả đạt được trong Tuần 12: Hoàn thành xuất sắc lộ trình thực tập DevOps/AWS toàn diện trong 12 tuần. Bàn giao Báo cáo Cuối khóa chất lượng cao, ghi lại chi tiết các triển khai kỹ thuật. Thực hiện dọn dẹp triệt để môi trường AWS, đảm bảo không phát sinh chi phí ngoài dự kiến. Củng cố kiến thức xuyên suốt các mảng Networking, Compute, Database, Security, DevOps và Serverless. Sẵn sàng cho buổi thuyết trình cuối cùng và các bước phát triển sự nghiệp Cloud/DevOps tiếp theo. "},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://quangtruong278.github.io/FCJBlog/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]